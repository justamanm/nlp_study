<综述>

[深度长文：NLP的巨人肩膀(上、下)](https://www.jiqizhixin.com/articles/2018-12-10-17)



### 词向量

<词向量，入门>

- [word2vec 中的数学原理详解](https://www.cnblogs.com/peghoty/p/3857839.html)（必看）
- [秒懂词向量Word2vec的本质 - 穆文的文章 - 知乎 ](https://zhuanlan.zhihu.com/p/26306795 )
- [word2vec是如何得到词向量的？ - crystalajj的回答 - 知乎](https://www.zhihu.com/question/44832436/answer/266068967)

见总结：词向量.md

用的多了自然就知道是什么了，优缺点有哪些



### 预训练--bert

<综述，词向量，预训练，elmo，bert>

[从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史 - 张俊林的文章 - 知乎](https://zhuanlan.zhihu.com/p/49271699)

[如何评价 BERT 模型？ - 夕小瑶的回答 - 知乎 ](https://www.zhihu.com/question/298203515/answer/516904100)



<词向量，elmo>

[理解Word Embedding，全面拥抱ELMO](https://blog.csdn.net/horizonheart/article/details/91043033)



<综述，词向量，预训练，bert>

[美团BERT的探索和实践](https://tech.meituan.com/2019/11/14/nlp-bert-practice.html)



### 文本相似度

<综述，相似度，表示型，交互型>

[文本匹配相关方向打卡点总结（数据，场景，论文，开源工具）](https://zhuanlan.zhihu.com/p/87384188)



<相似度，dssm>

[深度学习解决NLP问题：语义相似度计算](https://www.cnblogs.com/qniguoym/p/7772561.html)



<相似度，esim>

[短文本匹配的利器-ESIM](https://zhuanlan.zhihu.com/p/47580077)